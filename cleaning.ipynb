{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the step taken to clean the datasets\n",
    "- Removing duplicates based on 'raw_mail' column\n",
    "- Change the \"None\" to an actuall None value to all column\n",
    "- Remove email address that is not in the same format\n",
    "- Fill empty/none email address with bfill and ffill\n",
    "- Fill empty/none subject with bffill and ffill\n",
    "- Update the 'date' so it is in one format\n",
    "- Add malicious column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the libraries that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudDataframe = pd.read_json('datasets/raw/fradulent_emails.json', orient='index')\n",
    "phishingDataframe = pd.read_json('datasets/raw/phishing-chorpus.json', orient='index')\n",
    "enronDataframe = pd.read_csv('datasets/raw/enron-emails.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudDataframe = fraudDataframe.drop_duplicates(subset=\"raw_mail\")\n",
    "phishingDataframe = phishingDataframe.drop_duplicates(subset=\"raw_mail\")\n",
    "enronDataframe = enronDataframe.drop_duplicates(subset=\"raw_mail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a quick glance from all the 3 datasets, there are multiple inconsistensy that can be found in the format of the values. \n",
    "\n",
    "- from and to columns contains not only the emails\n",
    "- datetime isn't in one format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_mail    0\n",
      "subject     0\n",
      "from        0\n",
      "to          0\n",
      "status      0\n",
      "date        0\n",
      "body        0\n",
      "dtype: int64 \n",
      "\n",
      "raw_mail    0\n",
      "subject     0\n",
      "from        0\n",
      "to          0\n",
      "status      0\n",
      "date        0\n",
      "body        0\n",
      "dtype: int64 \n",
      "\n",
      "Unnamed: 0         0\n",
      "body               0\n",
      "subject        19187\n",
      "raw_mail           0\n",
      "from               0\n",
      "to             21847\n",
      "status        517401\n",
      "date               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(fraudDataframe.isna().sum(), '\\n') # contains none but isnt register as one\n",
    "print(phishingDataframe.isna().sum(), '\\n') # contains none but isnt register as one\n",
    "print(enronDataframe.isna().sum()) # contains null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it show above, only the enron datasets contains a null values while in fact all 3 datasets does contains a \"null\" values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check the values for a \"None\" in a string format we will infact found that the rest of the datasets does in fact contains a Null value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_mail      0\n",
      "subject      17\n",
      "from        365\n",
      "to          948\n",
      "status        0\n",
      "date        534\n",
      "body          0\n",
      "dtype: int64\n",
      "raw_mail     0\n",
      "subject     49\n",
      "from         4\n",
      "to           9\n",
      "status       5\n",
      "date         3\n",
      "body         0\n",
      "dtype: int64\n",
      "Unnamed: 0    0\n",
      "body          0\n",
      "subject       0\n",
      "raw_mail      0\n",
      "from          0\n",
      "to            0\n",
      "status        0\n",
      "date          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((fraudDataframe == \"None\").sum())\n",
    "print((phishingDataframe == \"None\").sum())\n",
    "print((enronDataframe == \"None\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the datasets to change the \"None\" values to an actual None, by applying a function to each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_mail    0\n",
      "subject     0\n",
      "from        0\n",
      "to          0\n",
      "status      0\n",
      "date        0\n",
      "body        0\n",
      "dtype: int64\n",
      "raw_mail      0\n",
      "subject      17\n",
      "from        948\n",
      "to          948\n",
      "status        0\n",
      "date        534\n",
      "body          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def updateToNone(val):\n",
    "    if val == \"None\":\n",
    "        return None\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "fraudDataframe['subject'] = fraudDataframe['subject'].apply(updateToNone)\n",
    "fraudDataframe['to'] = fraudDataframe['to'].apply(updateToNone)\n",
    "fraudDataframe['from'] = fraudDataframe['to'].apply(updateToNone)\n",
    "fraudDataframe['status'] = fraudDataframe['status'].apply(updateToNone)\n",
    "fraudDataframe['date'] = fraudDataframe['date'].apply(updateToNone)\n",
    "\n",
    "print((fraudDataframe == \"None\").sum())\n",
    "print(fraudDataframe.isna().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_mail    0\n",
      "subject     0\n",
      "from        0\n",
      "to          0\n",
      "status      0\n",
      "date        0\n",
      "body        0\n",
      "dtype: int64\n",
      "raw_mail      0\n",
      "subject      17\n",
      "from        948\n",
      "to          948\n",
      "status        0\n",
      "date        534\n",
      "body          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "phishingDataframe['subject'] = phishingDataframe['subject'].apply(updateToNone)\n",
    "phishingDataframe['to'] = phishingDataframe['to'].apply(updateToNone)\n",
    "phishingDataframe['from'] = phishingDataframe['to'].apply(updateToNone)\n",
    "phishingDataframe['status'] = phishingDataframe['status'].apply(updateToNone)\n",
    "phishingDataframe['date'] = phishingDataframe['date'].apply(updateToNone)\n",
    "\n",
    "print((fraudDataframe == \"None\").sum())\n",
    "print(fraudDataframe.isna().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the inconsistensy format of the email in columns \"from\" and \"to\" , we will used regex to extract the valid emails first then, fill the empty values with valid values from the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the pattern for capturing a valid email is \"[a-zA-Z0-9-_.]*@a-zA-Z0-9-]*(\\\\.[a-zA-Z]*)*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the patter will look for email that have a valid username + @ + domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\candi\\AppData\\Local\\Temp\\ipykernel_18780\\3334997152.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  notValidEmail = phishingDataframe['from'].str.contains('[a-zA-Z0-9-_.]*@a-zA-Z0-9-]*(\\.[a-zA-Z]*)*', regex=True) == False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4181"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notValidEmail = phishingDataframe['from'].str.contains('[a-zA-Z0-9-_.]*@a-zA-Z0-9-]*(\\.[a-zA-Z]*)*', regex=True) == False\n",
    "phishingDataframe[notValidEmail]['from'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\candi\\AppData\\Local\\Temp\\ipykernel_18780\\1799348055.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  notValidEmail = fraudDataframe['from'].str.contains('([a-zA-Z0-9-_.])*@([a-zA-Z0-9-])*(\\.[a-zA-Z]*)*', regex=True) == False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notValidEmail = fraudDataframe['from'].str.contains('([a-zA-Z0-9-_.])*@([a-zA-Z0-9-])*(\\.[a-zA-Z]*)*', regex=True) == False\n",
    "fraudDataframe[notValidEmail]['from'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\candi\\AppData\\Local\\Temp\\ipykernel_18780\\2401131589.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  notValidEmail = enronDataframe['to'].str.contains('([a-zA-Z0-9-_.])*@([a-zA-Z0-9-])*(\\.[a-zA-Z]*)*', regex=True) == False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notValidEmail = enronDataframe['to'].str.contains('([a-zA-Z0-9-_.])*@([a-zA-Z0-9-])*(\\.[a-zA-Z]*)*', regex=True) == False\n",
    "enronDataframe[notValidEmail]['to'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the 3 cells above shows the number of time that a row match pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedFrom = fraudDataframe['from'].str.extract('([a-zA-Z0-9-_.]*@[a-zA-Z0-9-]*(\\.[a-zA-Z]*)*)')\n",
    "parsedTo = fraudDataframe['to'].str.extract('([a-zA-Z0-9-_.]*@[a-zA-Z0-9-]*(\\.[a-zA-Z]*)*)')\n",
    "\n",
    "fraudDataframe['parsed_from'] = parsedFrom[0]\n",
    "fraudDataframe['parsed_to'] = parsedTo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedFrom = phishingDataframe['from'].str.extract('([a-zA-Z0-9-_.]*@[a-zA-Z0-9-]*(\\.[a-zA-Z]*)*)')\n",
    "parsedTo = phishingDataframe['to'].str.extract('([a-zA-Z0-9-_.]*@[a-zA-Z0-9-]*(\\.[a-zA-Z]*)*)')\n",
    "\n",
    "phishingDataframe['parsed_from'] = parsedFrom[0]\n",
    "phishingDataframe['parsed_to'] = parsedTo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedFrom = enronDataframe['from'].str.extract('([a-zA-Z0-9-_.]*@[a-zA-Z0-9-]*(\\.[a-zA-Z]*)*)')\n",
    "parsedTo = enronDataframe['to'].str.extract('([a-zA-Z0-9-_.]*@[a-zA-Z0-9-]*(\\.[a-zA-Z]*)*)')\n",
    "\n",
    "enronDataframe['parsed_from'] = parsedFrom[0]\n",
    "enronDataframe['parsed_to'] = parsedTo[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow is the kind of fields that wasnt register as an email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None 'undisclosed-recipients: ;' 'undisclosed-recipients:;' ''\n",
      " 'undisclosed recipients: ;' 'N/A <>, N/A <>' 'N/A <>']\n",
      "[None 'undisclosed-recipients: ;' 'undisclosed-recipients:;' ''\n",
      " 'undisclosed recipients: ;' 'N/A <>, N/A <>' 'N/A <>']\n",
      "['undisclosed-recipients: ;' '[removed]' None 'undisclosed-recipients:;'\n",
      " 'unlisted-recipients:; (no To-header on input)'\n",
      " '<Undisclosed-Recipient:;>' '=?euc-kr?B?u+e2+7nnu/W6rsbtwfawocG3?=' '']\n",
      "['undisclosed-recipients: ;' '[removed]' None 'undisclosed-recipients:;'\n",
      " 'unlisted-recipients:; (no To-header on input)'\n",
      " '<Undisclosed-Recipient:;>' '=?euc-kr?B?u+e2+7nnu/W6rsbtwfawocG3?=' '']\n"
     ]
    }
   ],
   "source": [
    "print(fraudDataframe[fraudDataframe['parsed_from'].isna()]['from'].unique())\n",
    "print(fraudDataframe[fraudDataframe['parsed_to'].isna()]['to'].unique())\n",
    "print(phishingDataframe[phishingDataframe['parsed_from'].isna()]['from'].unique())\n",
    "print(phishingDataframe[phishingDataframe['parsed_to'].isna()]['to'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishingDataframe['parsed_from'] = phishingDataframe['parsed_from'].ffill().bfill()\n",
    "fraudDataframe['parsed_from'] = fraudDataframe['parsed_from'].ffill().bfill()\n",
    "enronDataframe['parsed_from'] = enronDataframe['parsed_from'].ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishingDataframe['parsed_to'] = phishingDataframe['parsed_to'].ffill().bfill()\n",
    "fraudDataframe['parsed_to'] = fraudDataframe['parsed_to'].ffill().bfill()\n",
    "enronDataframe['parsed_to'] = enronDataframe['parsed_to'].ffill().bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all the datasets subject column contains a null value, we will fill this value using existing fields in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishingDataframe['subject'] = phishingDataframe.subject.ffill().bfill()\n",
    "fraudDataframe['subject'] = fraudDataframe.subject.ffill().bfill()\n",
    "enronDataframe['subject'] = enronDataframe.subject.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of row that have empty subject for phishingDataframe: 0\n",
      "Number of row that have empty subject for fraudDataframe: 0\n",
      "Number of row that have empty subject for enronDataframe: 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of row that have empty subject for phishingDataframe:', phishingDataframe.subject.isnull().sum())\n",
    "print('Number of row that have empty subject for fraudDataframe:', fraudDataframe.subject.isnull().sum())\n",
    "print('Number of row that have empty subject for enronDataframe:', enronDataframe.subject.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "enronDataframe['parsed_date'] = enronDataframe.date.apply(lambda date: parser.parse(date).isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill empty fields so no null exist by doing backward and forward fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudDataframe.date = fraudDataframe.date.ffill().bfill()\n",
    "phishingDataframe.date = phishingDataframe.date.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total date row that are not in format for phishingDataframe: 444\n",
      "Total date row that are not in format for phishingDataframe: 151\n"
     ]
    }
   ],
   "source": [
    "diff = phishingDataframe.shape[0] - phishingDataframe.date.str.contains('[A-Za-z]{0,3}, \\d* [A-Za-z]{0,3} \\d{4}').sum()\n",
    "print(\"Total date row that are not in format for phishingDataframe:\", diff)\n",
    "diff = fraudDataframe.shape[0] - fraudDataframe.date.str.contains('[A-Za-z]{0,3}, \\d* [A-Za-z]{0,3} \\d{4}').sum()\n",
    "print(\"Total date row that are not in format for phishingDataframe:\", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDate(date):\n",
    "    try:\n",
    "        return parser.parse(date).isoformat()\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\candi\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname CEST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "phishingDataframe['parsed_date'] = phishingDataframe.date.str.replace('\\.', ':', regex=True)\n",
    "phishingDataframe['parsed_date'] = phishingDataframe['parsed_date'].apply(parseDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual cleaning for cases that are to few to automate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishingDataframe.loc[821].parsed_date = parser.parse(\"Fri, 09 Jun 2006 08:23:29 +0500 (EST)\").isoformat()\n",
    "phishingDataframe.loc[892].parsed_date = parser.parse(\"Fri, 23 Jun 2006 13:25:46 -0100 (EST)\").isoformat()\n",
    "phishingDataframe.loc[896].parsed_date = parser.parse(\"Fri, 23 Jun 2006 21:36:05 +0800\").isoformat()\n",
    "phishingDataframe.loc[1066].parsed_date = parser.parse(\"Wed, 26 Jul 2006 09:48:28 -0800\").isoformat()\n",
    "phishingDataframe.loc[1067].parsed_date = parser.parse(\"Wed, 26 Jul 2006 12:50:48 -0600\").isoformat()\n",
    "phishingDataframe.loc[1072].parsed_date = parser.parse(\"Thu, 27 Jul 2006 03:06:10 -0800\").isoformat()\n",
    "phishingDataframe.loc[1074].parsed_date = parser.parse(\"Wed, 26 Jul 2006 15:24:52 -0500\").isoformat()\n",
    "phishingDataframe.loc[1075].parsed_date = parser.parse(\"Wed, 26 Jul 2006 15:43:42 -0500\").isoformat()\n",
    "phishingDataframe.loc[1076].parsed_date = parser.parse(\"Wed, 26 Jul 2006 19:03:49 -0300\").isoformat()\n",
    "phishingDataframe.loc[1077].parsed_date = parser.parse(\"Wed, 26 Jul 2006 19:35:02 -0300\").isoformat()\n",
    "phishingDataframe.loc[1095].parsed_date = parser.parse(\"31.07.2006\").isoformat()\n",
    "phishingDataframe.loc[1173].parsed_date = parser.parse(\"Thu, 3 Aug 2006 00:13:00 -0530\").isoformat()\n",
    "phishingDataframe.loc[2421].parsed_date = parser.parse(\"Tue, 09 Jan 2007 14:00:44 +0430\").isoformat()\n",
    "phishingDataframe.loc[3540].parsed_date = parser.parse(\"Sun, 10 Sep 2006 14:00:47 +0000\").isoformat()\n",
    "phishingDataframe.loc[3643].parsed_date = parser.parse(\"Fri, 09 Mar 2007 18:11:57 +0530\").isoformat()\n",
    "phishingDataframe.loc[3896].parsed_date = parser.parse(\"07.08.2006\").isoformat()\n",
    "phishingDataframe.loc[3963].parsed_date = parser.parse(\"Mon, 24 Feb 2003 17:32:08 +0000\").isoformat()\n",
    "phishingDataframe.loc[4117].parsed_date = parser.parse(\"Sun, 10 Sep 2006 12:08:54 -0300\").isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\candi\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname BST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "fraudDataframe['parsed_date'] = fraudDataframe.date.str.replace('\\.', ':', regex=True)\n",
    "fraudDataframe['parsed_date'] = fraudDataframe['parsed_date'].apply(parseDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(row):\n",
    "    if row.parsed_date == None:\n",
    "        try:\n",
    "            row.parsed_date = parser.parse(\n",
    "                re.search(\"([A-Za-z]{1,3}, \\d{0,2} [A-Za-z]* \\d{2,4} \\d{2}:\\d{2}:\\d{2} ((\\+|\\-)?\\d{4})?)\", \n",
    "                          row.date).group(1)).isoformat()\n",
    "            return row\n",
    "        except Exception as e:\n",
    "            return row\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "fraudDataframe = fraudDataframe.apply(myfunc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Updates for cases that are to few to automate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudDataframe.loc[542].parsed_date = parser.parse(\"Sun, 09 nov 2003 21:18:28\").isoformat()\n",
    "fraudDataframe.loc[1236].parsed_date = parser.parse(\"Tue, 09 nov 2004 15:38:35 -0300\").isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add prediction label that will be used in model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudDataframe['malicious'] = True\n",
    "phishingDataframe['malicious'] = True\n",
    "enronDataframe['malicious'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudDataframe.to_csv(path_or_buf='datasets/clean/fraud-emails.csv', index=False)\n",
    "phishingDataframe.to_csv(path_or_buf='datasets/clean/phishing-emails.csv', index=False)\n",
    "enronDataframe.to_csv(path_or_buf='datasets/clean/enron-emails.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f83a4b8e1c187aca35894c8eeaad8267ead7007e3a6e08dfe58ab16c9dd478f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
